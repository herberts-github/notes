{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[TOC]\n",
    "\n",
    "# 爬虫与反爬\n",
    "\n",
    "浏览器将 HTML 文档变成网页靠的是**渲染引擎**和**对应解释器**\n",
    "\n",
    "- 动态网页与网页源代码\n",
    "- 爬虫知识\n",
    "- 反爬虫概念与定义\n",
    "\n",
    "## 动态网页与网页源代码\n",
    "\n",
    "- 静态网页：没有数据库和不可交互的纯 HTML 网页，在页面生成后，不修改代码，网页显示内容和显示效果基本上不会发生变化\n",
    "- 动态网页：在不改变页面 HTML 代码情况下，能够根据不同用户或不同操作而显示不同内容的网页\n",
    "\n",
    "在爬虫领域中，**静态网页与动态网页的定义**与**传统定义**不同\n",
    "\n",
    "- 静态网页：网页主体内容渲染工作在服务器完成，并通过响应正文返回网页\n",
    "- 动态网页：主题内容或全部内容需要客户端执行 JavaScript 来计算或渲染网页\n",
    "- 网页源代码：未经过浏览器解释和 JavaScript 引擎渲染的文本，文本内容与 HTML 源文件的内容相同\n",
    "\n",
    "爬虫通过网络请求方式获取资源，**在得到的资源中，最重要的是响应正文**\n",
    "\n",
    "> 由于 Python、Java 和 PHP 没有 JavaScript 解释器和渲染引擎，无法渲染页面，只能爬取正文中的内容\n",
    ">\n",
    "> 在爬取动态网页数据，需要借助 JavaScript 解释器和渲染引擎将渲染后的网页代码以文本形式传给爬虫\n",
    "\n",
    "**渲染工具**：\n",
    "\n",
    "- Splash：异步 JavaScript 渲染服务\n",
    "- Selenium：自动化测试框架\n",
    "- Puppeteer：通过 DevTools 协议控制 Chrome 的 Node.js 库\n",
    "\n",
    "## 爬虫知识\n",
    "\n",
    "按照一定规则自动抓取互联网信息的程序，分为**通用爬虫**和**聚集爬虫**\n",
    "\n",
    "- 通用爬虫：在保持一定内容质量情况下爬虫尽可能多的站点\n",
    "- 聚集爬虫：在爬取少量站点的情况下尽可能保持精准的内容质量\n",
    "\n",
    "> 通常从一个或多个 URL 开始，在爬取过程中将新的并且符合要求的 URL 放入待爬队列，知道满足程序的停止条件\n",
    "\n",
    "**爬取过程**\n",
    "\n",
    "- 请求指定的 URL 获取响应正文\n",
    "- 解析响应正文内容并从中提取所需信息\n",
    "- 将上一步提取的信息保存到数据库或文件中\n",
    "\n",
    "**爬取商品信息**\n",
    "\n",
    "- 请求对应 URL 以获取服务器返回的相应正文\n",
    "- 使用 CSS 选择器或路径语言 XPATH 解析网页内容并提取所需商品信息\n",
    "- 将得到的数据存入文件或数据库\n",
    "\n",
    "\n",
    "以 Python 为例：提供对应模块实现网络请求，urllib 模块中的 request\n",
    "\n",
    "除了内置网络操作模块，也有第三方 Requests 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://iherberts.com'\n",
    "# 将服务器返回新存储在 resp 对象，需查看响应状态码和正文事，将对应内容取出来\n",
    "resp = requests.get(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "当响应正文是 HTML 文档，那么提取数据时还需要使用文档解析工具\n",
    "\n",
    "**解析库**：\n",
    "- lxml\n",
    "- BeautifulSoup\n",
    "- PyQuery 等等\n",
    "\n",
    "> **允许按照 CSS 选择器或 XPATH 的规则对文本进行定位和提取**\n",
    "\n",
    "CSS 选择器分为多种类型选择器用来选择符合语法要求的 HTML 内容"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【搭载HarmonyOS 2】HUAWEI Mate 40 Pro 4G 全网通 8GB+128GB（亮黑色） \n"
     ]
    }
   ],
   "source": [
    "# 1. 导入 Requests 和 Parsel 的 Selector\n",
    "import requests\n",
    "from parsel import Selector\n",
    "\n",
    "# 2. 定义目标 URL 并使用 Requests 的 get 方法请求指定的 URL\n",
    "url = 'https://www.vmall.com/product/10086300679105.html'\n",
    "\n",
    "# 向目标地址发起网络请求\n",
    "resp = requests.get(url)\n",
    "\n",
    "# 3. 根据商品名称的 HTML 标签和属性使用 CSS 选择器定位并提取文本\n",
    "# 使用响应正文初始化 Selector，得到实例\n",
    "sel = Selector(resp.text)\n",
    "\n",
    "# 根据 HTML 标签和样式属性从文本中提取商品名称\n",
    "res = sel.css('#pro-name::text').extract_first()\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 反爬虫的概念与定义\n",
    "\n",
    "**限制爬虫访问服务器资源或获取数据的行为**\n",
    "\n",
    "爬虫的访问速率和目的与正常用户访问速率和目的不同，大部分无节制地对目标应用进行爬取，给目标服务器带来 “垃圾流量”\n",
    "\n",
    "为了保证服务器正常运转或降低服务器压力与运营成本，不得不使出各种技术手段限制爬虫对服务器资源的访问\n",
    "\n",
    "- 请求限制\n",
    "- 拒绝响应\n",
    "- 客户端身份验证\n",
    "- 文本混淆\n",
    "- 使用动态渲染技术等\n",
    "\n",
    "**根据出发点划分**：\n",
    "\n",
    "- 主动性\n",
    "\n",
    "    使用技术手段区分正常用户和爬虫，并限制爬虫对网站的访问行为（验证请求头信息、限制访问频率、验证码等）\n",
    "\n",
    "- 被动性\n",
    "\n",
    "    为了提高用户体验或节省资源，间接提高爬虫访问难度（数据分段加载、点击切换标签页、鼠标悬停预览数据等）\n",
    "\n",
    "**从特点细致划分**：\n",
    "\n",
    "- 信息校验\n",
    "- 动态渲染\n",
    "- 文本混淆\n",
    "- 特征识别等\n",
    "\n",
    "> 同一种限制现象可被归类到不同的反爬虫类型中，如 通过 JavaScript 生成随机字符并将其放在请求头中发送，由服务器校验客户端身份的限制手段既可以是信息校验，也是动态渲染反爬虫\n",
    "\n",
    "反爬要了解网站流量情况，了解爬虫工程师常用手段，并从多个方面进行针对性防护，反爬的方案设计、实施和测试等都需要耗费大量时间\n",
    "\n",
    "经济方面开支：IP代理费用、云服务器费用、VIP 账户开通费用等\n",
    "\n",
    "还要耗费比反爬虫更多的时间，**当目标网站的算法或网页结构更改时，爬虫代码也需要对应的改变，甚至需要重写代码**\n",
    "\n",
    "**爬虫与反爬之间的对抗关系**\n",
    "\n",
    "| 序号 | 爬虫 | 反爬 |\n",
    "| --- | --- | --- |\n",
    "| 1 | 使用 Python 向目标网站发起请求，爬取数据 | 监控到异常流量，如果请求并非来自浏览器，则拒绝请求 |\n",
    "| 2 | 模拟浏览器标识，欺骗目标网站服务器 | 监控大量请求均来自同一个浏览器标识，考虑爬虫伪造，限制访问频率 |\n",
    "| 3 | 使用 IP 轮换或多机的方式对目标网站发起请求 | 在入口或表单处增加验证码，以区别正常用户和爬虫 |\n",
    "| 4 | 简单验证码通过代码识别，复杂验证码通过接入打码平台，对其发起请求 | 完善账号体系，规定只有 VIP 才能浏览关键信息，避免数据爬取 |\n",
    "| 5 | 注册多个账号并开通 VIP | 自定义混淆规则对网站的重要信息进行混淆，增加识别难度 |\n",
    "| 6 | 当解密成本较高时，采用屏幕截图方式获取关键数据 | 根据自动化测试框架或浏览器特征区别与爬虫 |\n",
    "| 7 | 成本太高，可能放弃爬取 | 成本太高，无法完全限制爬虫 |\n",
    "\n",
    "> **爬虫与反爬都是综合技能应用，其中涉及的技术知识包括 Web 开发、服务器、数据传输、编程语言特性和工具特性等**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}